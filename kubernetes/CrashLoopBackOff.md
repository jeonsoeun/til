# CrashLoopBackOff
새로 배포를 했는데 배포한 pod가 올라가지 못하고 CrashLoopBackOff 상태로 머물러 있었다. 계속 RESTART를 반복하고 있는 것 같았다. 

## 원인이 뭐지?
원인은 아주 다양하다고 한다. 그래서 해결법이 딱 나와있는게 아니더라.

## 해결은?
해결법을 찾아보는데 왜 자꾸 다들 상태를 보고 로그를 보라고하는지 처음엔 몰랐다. 그런데 그 이유가 **원인이 너무 다양하니까 해결법도 원인에 따라 다양한거였다.** 
### 원인을 찾는 과정
#### 통상적으로 하라고 하는거.
1. `$ kubectl -n <namespace-name> describe pod <pod name>` 으로 pod의 이벤트 기록을 확인한다.
2. `$ kubectl -n <namespace-name> logs -p  <pod name> `으로 로그를 살펴라.
3. 1번에 이벤트 기록이랑 exit code를 봐라
2. 2번으로 로그 확인해라.
### 내 원인과 해결
결론적으로 말하면 **내 원인은 그저 내가 올린 서버로직에 오류가 있어서 올라가다가 죽고를 반복한것**. 어째서 그전에 걸리지 않고 거기까지 갔는지 조금 당황스러웠지만, 수정하고 재배포하면서 상황은 일단락되었다.  
exit code는 1이였고, 이벤트 기록에는 별로 볼게 없었다. backoff 되었다는 한줄만 있던걸로 기억한다.  
혹시나 싶어서 로컬실행을 하다가 걸렸는지 아니면 로그를 보고 알았는지 기억이 잘 나지 않는데, 로그를 보고 알았던 것 같다. 그전에 2번을 실행했을때 **자꾸 pod가 없다** 그래서 파악이 오래걸렸다.